{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Exploratory Data Analysis: California Housing Dataset\n",
                "\n",
                "This notebook provides a comprehensive exploration of the California Housing dataset used for comparing Bayesian Hierarchical Models with Deep Neural Networks.\n",
                "\n",
                "**Objectives:**\n",
                "1. Understand the data distribution and feature characteristics\n",
                "2. Visualize spatial patterns in housing prices\n",
                "3. Examine relationships between features and target\n",
                "4. Validate the \"Small Tabular Regime\" hypothesis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "\n",
                "# Set style\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "sns.set_palette('husl')\n",
                "\n",
                "# Display settings\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.precision', 3)\n",
                "\n",
                "print(\"Libraries loaded successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading and Overview"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the processed dataset\n",
                "data_path = Path(\"../data/processed/housing_with_spatial_clusters.csv\")\n",
                "df = pd.read_csv(data_path)\n",
                "\n",
                "print(f\"Dataset Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
                "print(f\"\\nThis represents a 'Small Tabular Regime' (<20k samples)\")\n",
                "print(f\"where deep learning typically struggles against linear baselines.\\n\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data types and memory usage\n",
                "print(\"=\" * 50)\n",
                "print(\"DATA TYPES & MEMORY\")\n",
                "print(\"=\" * 50)\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Statistical Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Comprehensive statistics\n",
                "stats = df.describe().T\n",
                "stats['missing'] = df.isnull().sum()\n",
                "stats['missing_pct'] = (stats['missing'] / len(df) * 100).round(2)\n",
                "stats['dtype'] = df.dtypes\n",
                "\n",
                "print(\"=\" * 70)\n",
                "print(\"FEATURE STATISTICS SUMMARY\")\n",
                "print(\"=\" * 70)\n",
                "stats[['count', 'mean', 'std', 'min', '50%', 'max', 'missing_pct']]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Target Variable Analysis: Housing Price"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "# Distribution\n",
                "axes[0].hist(df['price'], bins=50, edgecolor='white', alpha=0.7, color='steelblue')\n",
                "axes[0].axvline(df['price'].mean(), color='red', linestyle='--', label=f\"Mean: {df['price'].mean():.2f}\")\n",
                "axes[0].axvline(df['price'].median(), color='orange', linestyle='--', label=f\"Median: {df['price'].median():.2f}\")\n",
                "axes[0].set_xlabel('Housing Price (scaled)')\n",
                "axes[0].set_ylabel('Frequency')\n",
                "axes[0].set_title('Price Distribution')\n",
                "axes[0].legend()\n",
                "\n",
                "# Box plot\n",
                "axes[1].boxplot(df['price'], vert=True)\n",
                "axes[1].set_ylabel('Price')\n",
                "axes[1].set_title('Price Box Plot (Outlier Detection)')\n",
                "\n",
                "# QQ plot for normality\n",
                "from scipy import stats as scipy_stats\n",
                "scipy_stats.probplot(df['price'], dist=\"norm\", plot=axes[2])\n",
                "axes[2].set_title('QQ Plot (Normality Check)')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../results/figures/eda_target_distribution.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"Skewness: {df['price'].skew():.3f}\")\n",
                "print(f\"Kurtosis: {df['price'].kurtosis():.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Correlations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation matrix\n",
                "numeric_cols = ['price', 'median_income', 'house_age', 'avg_rooms', \n",
                "                'avg_bedrooms', 'population', 'latitude', 'longitude']\n",
                "corr_matrix = df[numeric_cols].corr()\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(10, 8))\n",
                "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
                "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', \n",
                "            cmap='RdBu_r', center=0, square=True,\n",
                "            linewidths=0.5, ax=ax)\n",
                "ax.set_title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../results/figures/eda_correlation_matrix.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "# Top correlations with price\n",
                "print(\"\\n\" + \"=\" * 40)\n",
                "print(\"CORRELATIONS WITH PRICE\")\n",
                "print(\"=\" * 40)\n",
                "price_corr = corr_matrix['price'].drop('price').sort_values(key=abs, ascending=False)\n",
                "for feat, corr in price_corr.items():\n",
                "    print(f\"{feat:20s}: {corr:+.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Spatial Analysis: Geographic Patterns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
                "\n",
                "# Price by location\n",
                "scatter1 = axes[0].scatter(df['longitude'], df['latitude'], \n",
                "                           c=df['price'], cmap='viridis', \n",
                "                           alpha=0.5, s=10)\n",
                "axes[0].set_xlabel('Longitude')\n",
                "axes[0].set_ylabel('Latitude')\n",
                "axes[0].set_title('Housing Prices by Location')\n",
                "plt.colorbar(scatter1, ax=axes[0], label='Price')\n",
                "\n",
                "# Clusters by location\n",
                "if 'spatial_cluster' in df.columns:\n",
                "    scatter2 = axes[1].scatter(df['longitude'], df['latitude'], \n",
                "                               c=df['spatial_cluster'], cmap='tab10', \n",
                "                               alpha=0.5, s=10)\n",
                "    axes[1].set_xlabel('Longitude')\n",
                "    axes[1].set_ylabel('Latitude')\n",
                "    axes[1].set_title('Spatial Clusters (Hierarchical Groups)')\n",
                "    plt.colorbar(scatter2, ax=axes[1], label='Cluster ID')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../results/figures/eda_spatial_patterns.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "if 'spatial_cluster' in df.columns:\n",
                "    print(f\"\\nNumber of Spatial Clusters: {df['spatial_cluster'].nunique()}\")\n",
                "    print(f\"Samples per Cluster (mean): {len(df) / df['spatial_cluster'].nunique():.0f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Key Feature: Income vs Price Relationship"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Overall relationship\n",
                "axes[0].scatter(df['median_income'], df['price'], alpha=0.3, s=5)\n",
                "z = np.polyfit(df['median_income'], df['price'], 1)\n",
                "p = np.poly1d(z)\n",
                "x_line = np.linspace(df['median_income'].min(), df['median_income'].max(), 100)\n",
                "axes[0].plot(x_line, p(x_line), 'r-', linewidth=2, label=f'Linear fit (r={price_corr[\"median_income\"]:.3f})')\n",
                "axes[0].set_xlabel('Median Income')\n",
                "axes[0].set_ylabel('Price')\n",
                "axes[0].set_title('Income vs Price: Linear Relationship')\n",
                "axes[0].legend()\n",
                "\n",
                "# By cluster (key insight for Bayesian model)\n",
                "if 'spatial_cluster' in df.columns:\n",
                "    for cluster in df['spatial_cluster'].unique():\n",
                "        cluster_df = df[df['spatial_cluster'] == cluster]\n",
                "        axes[1].scatter(cluster_df['median_income'], cluster_df['price'], \n",
                "                       alpha=0.5, s=10, label=f'Cluster {cluster}')\n",
                "    axes[1].set_xlabel('Median Income')\n",
                "    axes[1].set_ylabel('Price')\n",
                "    axes[1].set_title('Income vs Price BY CLUSTER\\n(Demonstrates Heterogeneous Slopes)')\n",
                "    axes[1].legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=8)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../results/figures/eda_income_price_clusters.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"KEY INSIGHT: Income-Price relationship varies by cluster!\")\n",
                "print(\"This is the heterogeneity that Bayesian Hierarchical Models capture.\")\n",
                "print(\"=\" * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Cluster-Level Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if 'spatial_cluster' in df.columns:\n",
                "    cluster_stats = df.groupby('spatial_cluster').agg({\n",
                "        'price': ['mean', 'std', 'count'],\n",
                "        'median_income': 'mean',\n",
                "        'house_age': 'mean'\n",
                "    }).round(3)\n",
                "    \n",
                "    cluster_stats.columns = ['price_mean', 'price_std', 'n_samples', \n",
                "                             'income_mean', 'age_mean']\n",
                "    cluster_stats = cluster_stats.sort_values('price_mean', ascending=False)\n",
                "    \n",
                "    print(\"=\" * 70)\n",
                "    print(\"CLUSTER-LEVEL SUMMARY STATISTICS\")\n",
                "    print(\"=\" * 70)\n",
                "    display(cluster_stats)\n",
                "    \n",
                "    # Variance analysis\n",
                "    print(f\"\\nBetween-cluster price variance: {cluster_stats['price_mean'].var():.4f}\")\n",
                "    print(f\"Within-cluster price variance (avg): {cluster_stats['price_std'].mean()**2:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Data Regime Analysis: Why This Favors Linear Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sample size vs feature count\n",
                "n_samples = len(df)\n",
                "n_features = len(numeric_cols) - 1  # Exclude target\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"DATA REGIME ANALYSIS\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"\\nSample Size (n):        {n_samples:,}\")\n",
                "print(f\"Feature Count (p):      {n_features}\")\n",
                "print(f\"Samples per Feature:    {n_samples / n_features:.0f}\")\n",
                "print(f\"\\nRegime Classification:  {'SMALL TABULAR' if n_samples < 20000 else 'MEDIUM/LARGE'}\")\n",
                "print()\n",
                "print(\"Implications:\")\n",
                "print(\"- High risk of overfitting for complex models (NNs)\")\n",
                "print(\"- Linear models benefit from implicit regularization\")\n",
                "print(\"- Bayesian priors provide effective capacity control\")\n",
                "print(\"- Deep learning requires N >> 100k to outperform in tabular data\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Summary & Key Takeaways"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\"EDA SUMMARY: KEY FINDINGS\")\n",
                "print(\"=\" * 70)\n",
                "print(\"\"\"\n",
                "1. SMALL TABULAR REGIME\n",
                "   - Dataset size favors low-variance models (Linear, Bayesian)\n",
                "   - Deep NNs likely to overfit without massive regularization\n",
                "\n",
                "2. STRONG LINEAR SIGNAL\n",
                "   - Median income shows r ≈ 0.7 correlation with price\n",
                "   - Primary relationship is approximately linear\n",
                "\n",
                "3. SPATIAL HETEROGENEITY EXISTS\n",
                "   - Income-price slopes vary meaningfully by cluster\n",
                "   - Hierarchical Bayesian models can capture this explicitly\n",
                "   - MLPs aggregate this into opaque non-linear mappings\n",
                "\n",
                "4. RESEARCH VALUE\n",
                "   - Validates use of Bayesian partial pooling for spatial data\n",
                "   - Demonstrates practical limits of deep learning on tabular data\n",
                "   - Supports Occam's Razor in model selection\n",
                "\"\"\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}